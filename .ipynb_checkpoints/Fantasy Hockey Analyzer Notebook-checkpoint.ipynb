{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d4545d",
   "metadata": {},
   "source": [
    "This is my Fantasy Hockey Analyzer. The purpose of this project is to predict the fantasy hockey output of individual skaters based on stats from previous years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d8990",
   "metadata": {},
   "source": [
    "Section 1: Modules Used\n",
    "\n",
    "The following is a list of modules that I used and the reason why they were used:\n",
    "\n",
    "-os: to allow the program to read data in the repository\n",
    "\n",
    "-numpy: basic math operations\n",
    "\n",
    "-pandas: all dataframe operations/data storage/data cleaning\n",
    "\n",
    "-various sklearn: all machine learning operations/analysis\n",
    "\n",
    "In addition to these modules, I also have a custom module that contains helper functions that help in data cleaning/accuracy evaluation. These functions are contained in the \"my_module.py\" file in the repository. If you are interested in taking a look at these functions, they are available at https://github.com/chrisberry888/FantasyHockeyAnalyzer in the \"my_module.py\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ca7f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import block\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import clone\n",
    "\n",
    "import my_module as mx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9221715",
   "metadata": {},
   "source": [
    "Section 2: Data Gathering and Cleaning\n",
    "\n",
    "The ultimate goal of this project is to predict the number of fantasy points that a given player will have in the 2022-2023 season. Different fantasy leagues have different points breakdowns, but my current league has a points breakdown as described in the \"points_dict\" variable in the following code block. For example, each player gets 5 fantasy points for a goal, 3 for an assist, and so on. Of course, this can be changed if a different league has a different points breakdown.\n",
    "\n",
    "To accomplish this all, I have gathered data from rotowire.com and moneypuck.com. The Moneypuck data contains just about every advanced stat you could think of in a variety of different situations (5-on-5, 5-on-4, etc). However, for the sake of this project we will only use their data that describes a player's output in all of their situations. The only stat we need that can't be calculated using the Moneypuck data is +/-; Rotowire has +/- available, so I'm using that dataset.\n",
    "\n",
    "Data from these sets start from the 2010-2011 season and stretch to the 2021-2022 season. All of the major data gathering and cleaning occurs in the next three code blocks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3439153",
   "metadata": {},
   "source": [
    "The following block does all of the prep work before we start to read the data. It first establishes where the data is stored in the repository so that it can be read by the program. It then creates a list of labels that will be used by the rotowire data (the rotowire dataset is formatted differently than the moneypuck dataset, so we need to do this extra step before proceeding). It then establishes a points breakdown for each relevant stat; this is used later on to calculate fantasy points for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025360ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The current working directory is the main repository directory; these lines set the path to where the data is\n",
    "path = os.getcwd()\n",
    "data_path = path + '/data'\n",
    "\n",
    "#This array makes it easier to format the rotowire data\n",
    "rw_labels = [\"name\", \"Team\", \"Pos\", \"Games\", \"Goals\", \"Assists\", \"Pts\", \"+/-\", \"PIM\", \"SOG\", \"GWG\", \"PP_Goals\", \"PP_Assists\", \"SH_Goals\", \"SH_Assists\", \"Hits\", \"Blocked_Shots\"]\n",
    "\n",
    "#This is the breakdown of how many fantasy points a player gets for each category\n",
    "points_dict = {\"Goals\":5, \"Assists\":3, \"+/-\":1.5, \"PIM\":-0.25, \"PP_Goals\":4, \"PP_Assists\":2, \"SH_Goals\":6, \"SH_Assists\":4, \"Faceoffs_Won\":0.25, \"Faceoffs_Lost\":-0.15, \"Hits\":0.5, \"Blocked_Shots\":0.75 }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90783959",
   "metadata": {},
   "source": [
    "The following block takes all of the data in the repository and turns it into year-by-year player data. For each year from 2010 to 2024, the for-loop reads the rotowire and moneypuck data from the csv files in the repository, merges the datasets together, calculates the player's fantasy points for that season, does some formatting, then adds it to the \"yearly_player_data\" list. This list can be used later on for turning into ML-readable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c98a1-14a6-4c26-be56-b1bd7d34d1d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd80476",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot mask with non-boolean array containing NA / NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m moneypuck_df = pd.read_csv(data_path + \u001b[33m'\u001b[39m\u001b[33m/moneypuck_data/moneypuck\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m.format(\u001b[38;5;28mstr\u001b[39m(i)))\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#Gets rid of Elias Pettersson becuase he's fucking up my program lol\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m rotowire_df.drop(\u001b[43mrotowire_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrotowire_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mElias Pettersson\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m.index, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m moneypuck_df.drop(moneypuck_df[moneypuck_df[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m].str.contains(\u001b[33m'\u001b[39m\u001b[33mElias Pettersson\u001b[39m\u001b[33m'\u001b[39m)].index, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#Formats the rotowire data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/FantasyHockeyAnalyzer--xe1H7eQ/lib/python3.13/site-packages/pandas/core/frame.py:4103\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.where(key)\n\u001b[32m   4102\u001b[39m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   4104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_bool_array(key)\n\u001b[32m   4106\u001b[39m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[32m   4107\u001b[39m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/FantasyHockeyAnalyzer--xe1H7eQ/lib/python3.13/site-packages/pandas/core/common.py:136\u001b[39m, in \u001b[36mis_bool_indexer\u001b[39m\u001b[34m(key)\u001b[39m\n\u001b[32m    132\u001b[39m     na_msg = \u001b[33m\"\u001b[39m\u001b[33mCannot mask with non-boolean array containing NA / NaN values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lib.is_bool_array(key_array, skipna=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    134\u001b[39m         \u001b[38;5;66;03m# Don't raise on e.g. [\"A\", \"B\", np.nan], see\u001b[39;00m\n\u001b[32m    135\u001b[39m         \u001b[38;5;66;03m#  test_loc_getitem_list_of_labels_categoricalindex_with_na\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(na_msg)\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Cannot mask with non-boolean array containing NA / NaN values"
     ]
    }
   ],
   "source": [
    "#I have data from the 2010-2011 season through the 2024-2025 season. df_filtered = df[~df['name'].str.contains('Elias Pettersson')]\n",
    "#By the end of this block, there will be 14 seasons-worth of data in the \"data\" variable\n",
    "yearly_player_data = []\n",
    "\n",
    "for i in range(2010, 2025):\n",
    "    \n",
    "    new_data = []\n",
    "    \n",
    "    #Imports the rotowire and moneypuck datasets from the selected year into rotowire_df and moneypuck_df\n",
    "    rotowire_df = pd.read_csv(data_path + '/rotowire_data/rotowire{}.csv'.format(str(i)), names=rw_labels, header=None)\n",
    "    moneypuck_df = pd.read_csv(data_path + '/moneypuck_data/moneypuck{}.csv'.format(str(i)))\n",
    "\n",
    "    #Formats the rotowire data\n",
    "    rotowire_df = rotowire_df.iloc[2:]\n",
    "\n",
    "    #Replace arizona with utah\n",
    "    rotowire_df['Team'] = rotowire_df['Team'].replace('ARI', 'UTA')\n",
    "    moneypuck_df['team'] = moneypuck_df['team'].replace('ARI', 'UTA')\n",
    "    \n",
    "    #The Moneypuck data has information about 5-on-5, 5-on-4, 4-on-5, other, and all.\n",
    "    #For this project I'm just focused on \"all\" since I suspect it'll give me the best results.\n",
    "    moneypuck_df = moneypuck_df[moneypuck_df[\"situation\"] == \"all\"]\n",
    "    \n",
    "    #Combines the \"Name\" and \"Team\" columns (There are some players with the same name on different teams)\n",
    "    rotowire_df[\"name\"] = rotowire_df[\"name\"] + \"-\" + rotowire_df[\"Team\"]\n",
    "    moneypuck_df[\"name\"] = moneypuck_df[\"name\"] + \"-\" + moneypuck_df[\"team\"]\n",
    "    \n",
    "    #Merges the rotowire and moneypuck dataframes\n",
    "    new_data = pd.merge(rotowire_df, moneypuck_df, on=\"name\")\n",
    "    \n",
    "    #Changes the name of a few columns in the new dataframe\n",
    "    new_data = new_data.rename(columns={\"name\":\"Name\",\"faceoffsWon\":\"Faceoffs_Won\",\"faceoffsLost\":\"Faceoffs_Lost\"})\n",
    "    \n",
    "    #This section calculates each player's total fantasy output for that year\n",
    "    cols = new_data.columns\n",
    "    fant_points = [0 for i in range(len(new_data))]\n",
    "    for i in range(len(new_data)):\n",
    "        for j in range(len(new_data.iloc[i])):\n",
    "            mult = points_dict.get(cols[j], 0)\n",
    "            if mult != 0:\n",
    "                fant_points[i] += mult*int(new_data.iloc[i, j])\n",
    "    \n",
    "    #Adds the players' fantasy points to the new_data dataframe\n",
    "    new_data[\"Fantasy_Points\"] = fant_points\n",
    "    \n",
    "    new_data = new_data.drop_duplicates()\n",
    "    \n",
    "    #Adds new_data to the \"data\" array\n",
    "    yearly_player_data.append(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b2103-e341-4fab-be76-ac4aae36335b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56588866",
   "metadata": {},
   "source": [
    "The following block takes the yearly data and turns it into ML-readable data. For this project, I am creating different models that use data from the past one year, the past two years, and the past three years, and seeing how much they differ in terms of efficacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ea883",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_one_year = pd.DataFrame()\n",
    "ml_data_two_year = pd.DataFrame()\n",
    "ml_data_three_year = pd.DataFrame()\n",
    "for i in range(2011, 2025):\n",
    "    arr = [yearly_player_data[i-2011]]\n",
    "    points_df = yearly_player_data[i-2010]\n",
    "    temp = mx.merge_dataframes(arr, points_df)\n",
    "    ml_data_one_year = pd.concat([ml_data_one_year, temp], ignore_index=True)\n",
    "    \n",
    "for i in range(2012, 2025):\n",
    "    arr = [yearly_player_data[i-2012], yearly_player_data[i-2011]]\n",
    "    points_df = yearly_player_data[i-2010]\n",
    "    temp = mx.merge_dataframes(arr, points_df)\n",
    "    ml_data_two_year = pd.concat([ml_data_two_year, temp], ignore_index=True)\n",
    "    \n",
    "for i in range(2013, 2025):\n",
    "    arr = [yearly_player_data[i-2013], yearly_player_data[i-2012], yearly_player_data[i-2011]]\n",
    "    points_df = yearly_player_data[i-2010]\n",
    "    temp = mx.merge_dataframes(arr, points_df)\n",
    "    ml_data_three_year = pd.concat([ml_data_three_year, temp], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c27458-1e11-4330-838c-c2b531e8c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ml_data_three_year.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119148c8-5fd1-44a3-a1ba-f7ea60d81f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7b65d-3098-4910-8d75-a8070e13f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(ml_data_three_year.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c03981",
   "metadata": {},
   "source": [
    "Section 3: ML Model Training\n",
    "\n",
    "Now that we have the data that ml models can read, we can now train the models. For this project, I'm using multi-layer perceptrons (MLPRegressor) and Random Forests (RandomForestRegressor). I'm making six total models: a MLP each for the one- two- and three-year data, and a Random Forest each for the one- two- and three-year data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a38065",
   "metadata": {},
   "source": [
    "ONE YEAR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of models per model type (mpt = models per type)\n",
    "mpt = 1\n",
    "\n",
    "arr = mx.separate_fantasy_points(ml_data_one_year)\n",
    "X = mx.reformat_df(arr[0])\n",
    "y = arr[1]\n",
    "\n",
    "\n",
    "one_year_regr = MLPRegressor(max_iter=1000)\n",
    "\n",
    "\n",
    "one_year_RF = RandomForestRegressor()\n",
    "\n",
    "\n",
    "one_year_regr_models = mx.sim(one_year_regr, X, y, mpt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_RF_models = mx.sim(one_year_RF, X, y, mpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb743c",
   "metadata": {},
   "source": [
    "TWO YEAR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd87cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = mx.separate_fantasy_points(ml_data_two_year)\n",
    "X = mx.reformat_df(arr[0])\n",
    "y = arr[1]\n",
    "\n",
    "\n",
    "two_year_regr = MLPRegressor(max_iter=1000)\n",
    "\n",
    "two_year_RF = RandomForestRegressor()\n",
    "\n",
    "two_year_regr_models = mx.sim(two_year_regr, X, y, mpt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_year_RF_models = mx.sim(two_year_RF, X, y, mpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e250362b",
   "metadata": {},
   "source": [
    "THREE YEAR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0036bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = mx.separate_fantasy_points(ml_data_three_year)\n",
    "X = mx.reformat_df(arr[0])\n",
    "y = arr[1]\n",
    "\n",
    "three_year_regr = MLPRegressor(max_iter=1000)\n",
    "\n",
    "three_year_RF = RandomForestRegressor()\n",
    "\n",
    "three_year_regr_models= mx.sim(three_year_regr, X, y, mpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a39b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_year_RF_models= mx.sim(three_year_RF, X, y, mpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867211c",
   "metadata": {},
   "source": [
    "Section 4: Analysis\n",
    "\n",
    "Now that we have the models trained, we can analyze them. We'll be analyzing the data in two ways: first, we'll see how accurate the actual points predictions are using the mean_absolute_error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''y_pred = one_year_regr.predict(X_test_one)\n",
    "print(mean_absolute_error(y_test_one, y_pred))\n",
    "\n",
    "y_pred = two_year_regr.predict(X_test_two)\n",
    "print(mean_absolute_error(y_test_two, y_pred))\n",
    "\n",
    "y_pred = three_year_regr.predict(X_test_three)\n",
    "print(mean_absolute_error(y_test_three, y_pred))\n",
    "\n",
    "y_pred = one_year_RF.predict(X_test_one)\n",
    "print(mean_absolute_error(y_test_one, y_pred))\n",
    "\n",
    "y_pred = two_year_RF.predict(X_test_two)\n",
    "print(mean_absolute_error(y_test_two, y_pred))\n",
    "\n",
    "y_pred = three_year_RF.predict(X_test_three)\n",
    "print(mean_absolute_error(y_test_three, y_pred))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2621cff7",
   "metadata": {},
   "source": [
    "The MAE for all of the models range between around 70 and around 95. Given that most players in the league finish with a fantasy point total in the hundreds, we can see that the predicted points values aren't very accurate to the real-life values. However, we are less concerned with the actual points total that a player will have, and more concerned with their rank within the rest of the league. To look at this, we will rank the players both in terms of predicted fantasy points for a season, and actual fantasy points for a season. (I'll incorporate this at a later time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d5307",
   "metadata": {},
   "source": [
    "Section 5: Predictions for Next Year\n",
    "\n",
    "Now that we've taken a look at the accuracy of the model, we'll see what the models think will happen in the 2022-2023 season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_preds = []\n",
    "\n",
    "one_year_pred = yearly_player_data[14].copy()\n",
    "one_year_pred.drop(columns=[\"Fantasy_Points\"], inplace=True)\n",
    "dfs1 = []\n",
    "for i in range(mpt):\n",
    "    dfs1.append(mx.get_name_predictions(one_year_regr_models[i], one_year_pred))\n",
    "big_preds.extend(dfs1)\n",
    "\n",
    "one_year_pred = yearly_player_data[14].copy()\n",
    "one_year_pred.drop(columns=[\"Fantasy_Points\"], inplace=True)\n",
    "dfs2 = []\n",
    "for i in range(mpt):\n",
    "    dfs2.append(mx.get_name_predictions(one_year_RF_models[i], one_year_pred))\n",
    "big_preds.extend(dfs2)\n",
    "\n",
    "two_year_pred = [yearly_player_data[i] for i in [13,14]]\n",
    "two_year_pred = mx.merge_dataframes(two_year_pred, yearly_player_data[12])\n",
    "two_year_pred.drop(columns=[\"Predicted_Fantasy_Points\"], inplace=True)\n",
    "dfs3 = []\n",
    "for i in range(mpt):\n",
    "    dfs3.append(mx.get_name_predictions(two_year_regr_models[i], two_year_pred))\n",
    "big_preds.extend(dfs3)\n",
    "\n",
    "two_year_pred = [yearly_player_data[i] for i in [13,14]]\n",
    "two_year_pred = mx.merge_dataframes(two_year_pred, yearly_player_data[12])\n",
    "two_year_pred.drop(columns=[\"Predicted_Fantasy_Points\"], inplace=True)\n",
    "dfs4 = []\n",
    "for i in range(mpt):\n",
    "    dfs4.append(mx.get_name_predictions(two_year_RF_models[i], two_year_pred))\n",
    "big_preds.extend(dfs4)\n",
    "\n",
    "three_year_pred = [yearly_player_data[i] for i in [12,13,14]]\n",
    "three_year_pred = mx.merge_dataframes(three_year_pred, yearly_player_data[12])\n",
    "three_year_pred.drop(columns=[\"Predicted_Fantasy_Points\"], inplace=True)\n",
    "dfs5 = []\n",
    "for i in range(mpt):\n",
    "    dfs5.append(mx.get_name_predictions(three_year_regr_models[i], three_year_pred))\n",
    "big_preds.extend(dfs5)\n",
    "\n",
    "three_year_pred = [yearly_player_data[i] for i in [12,13,14]]\n",
    "three_year_pred = mx.merge_dataframes(three_year_pred, yearly_player_data[12])\n",
    "three_year_pred.drop(columns=[\"Predicted_Fantasy_Points\"], inplace=True)\n",
    "dfs6 = []\n",
    "for i in range(mpt):\n",
    "    dfs6.append(mx.get_name_predictions(three_year_RF_models[i], three_year_pred))\n",
    "big_preds.extend(dfs6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# one_year_df = mx.sum_predictions(dfs1)\n",
    "# one_year_df.sort_values(by=\"Prediction\", ascending=False, inplace=True)\n",
    "# pd.options.display.max_rows = None\n",
    "# display(one_year_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# one_year_df = mx.sum_predictions(dfs2)\n",
    "# one_year_df.sort_values(by=\"Prediction\", ascending=False, inplace=True)\n",
    "# pd.options.display.max_rows = None\n",
    "# display(one_year_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_year_df = mx.sum_predictions(dfs3)\n",
    "# two_year_df.sort_values(by=\"Prediction\", ascending=False, inplace=True)\n",
    "# pd.options.display.max_rows = None\n",
    "# display(two_year_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_year_df = mx.sum_predictions(dfs4)\n",
    "# two_year_df.sort_values(by=\"Prediction\", ascending=False, inplace=True)\n",
    "# pd.options.display.max_rows = None\n",
    "# display(two_year_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three_year_df = mx.sum_predictions(dfs5)\n",
    "# three_year_df.sort_values(by=\"Prediction\", ascending=False, inplace=True)\n",
    "# pd.options.display.max_rows = None\n",
    "# display(three_year_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a76983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three_year_df = mx.sum_predictions(dfs6)\n",
    "# three_year_df.sort_values(by=\"Prediction\", ascending=False, inplace=True)\n",
    "# pd.options.display.max_rows = None\n",
    "# display(three_year_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_preds_df = mx.sum_predictions(big_preds)\n",
    "extended_preds_df['Prediction'] = extended_preds_df['Prediction'] / (6 * mpt)\n",
    "extended_preds_df.sort_values(by=\"Prediction\", ascending=False, inplace=True)\n",
    "extended_preds_df.reset_index(drop=True, inplace=True)\n",
    "pd.options.display.max_rows = None\n",
    "display(extended_preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc5374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc034486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac4eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb70c0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9a8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6796ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839abefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e19ccc29",
   "metadata": {},
   "source": [
    "Section 6: Conclusion and Next Steps\n",
    "\n",
    "The predictions made by all of these models make sense; all of the predicted top players are still some of the top players in the league this year, and many of the predictions match up with predictions made by ESPN. One step that could be done is aggregating the six models together to get an average points prediction, and listing the players that way. Another thing that can be done to improve the models is incorporate injury data; there are some elite players that were injured in some part of the past three years, and their predictions are more pessemistic than other players. Another improvement could be to try and scale for the COVID-shortened 2019-2020 and 2020-2021 seasons. There were many logistical issues that contributed to fewer games and lower scoring in those years, and a scaling of goal/assist values could be beneficial to the models.\n",
    "\n",
    "Overall, I'm happy with how the models performed. After the 2022-2023 regular season, I will see how well they were able to predict some of the outliers, and I'll use that new data to make a prediction for the 2023-2024 season.\n",
    "\n",
    "UPDATE 9/8/23\n",
    "\n",
    "I updated the program to make 100 models each for the 6 different combinations of model type and years-scope, for a total of 600 models. I then took the predictions from those 600 models and averaged them out to get a final list of NHL players.\n",
    "\n",
    "I used this list to draft my current fantasy NHL team. While most of the predictions aligned with ESPN's predictions, there were some players whom my model thought were underrated. The most notable example is Shane Pinto, currently of the Ottawa Senators; while ESPN believes he should be ranked near 300th among skaters (low enough where he doesn't have a position rank), my model predicts that he will be a top 80 skater this year. Other notable skaters that my model believes in are Brayden Schenn of the Blues, Ryan Hartman of the Wild, Ty Dellandrea of the Stars, and Mikael Backlund of the Flames. Time will tell if these predictions pan out.\n",
    "\n",
    "UPDATE 10/3/25\n",
    "\n",
    "I have no clue why this didn't update last year. I updated and ran this program last year, I used it to draft my team, and my team made the playoffs but lost in the semifinals. I'm happy with how it performed.\n",
    "\n",
    "I'm updating the program now to draft my team for the 2025-26 season."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a62a598",
   "metadata": {},
   "source": [
    "ACKNOWLEDGEMENTS:\n",
    "\n",
    "Thank you to Rotowire and Moneypuck for making your NHL data easy for someone like me to utilize in a project like this, and thank you to Peter Tanner of Moneypuck not just for creating such a valuable resource, but for being responsive to questions I was having about your dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
